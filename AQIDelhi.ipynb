{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to download the data : 78.64291167259216 \n"
     ]
    }
   ],
   "source": [
    "#defining a function to retive the data for the required number of months and years\n",
    "def html_retrive():\n",
    "    for year in range(2013,2019):\n",
    "        for month in range(0,13):\n",
    "            if (month<10):\n",
    "                url = 'https://en.tutiempo.net/climate/0{}-{}/ws-421810.html'.format(month,year)\n",
    "            else:\n",
    "                url = 'https://en.tutiempo.net/climate/{}-{}/ws-421810.html'.format(month,year)\n",
    "            texts = requests.get(url)  #requesting the data from Url\n",
    "            text_utf=texts.text.encode(\"utf = 8\")  # encoding html texts for some unnessary html texts\n",
    "            if not os.path.exists(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\html_data\\\\{}\".format(year)):  # Checking if we have the data folders\n",
    "                os.makedirs(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\html_data\\\\{}\".format(year)) # Creating a directory of year if not present  \n",
    "            with open(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\html_data\\\\{}\\\\{}.html\".format(year,month),\"wb\") as output: #creating different months directories .html files \n",
    "                output.write(text_utf)\n",
    "            sys.stdout.flush()  # flush everything that is getting created in the file \n",
    "if __name__ == \"__main__\":\n",
    "    start_time=time.time() # recording the time it takes for the program to run\n",
    "    html_retrive()\n",
    "    stop_time = time.time()\n",
    "    print(\"time taken to download the data : {} \".format(stop_time-start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dependent variable and performing feature engineering\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def avg_data_2013(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2013.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2013\n",
    "def avg_data_2014(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2014.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2014\n",
    "def avg_data_2015(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2015.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2015\n",
    "def avg_data_2016(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2016.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2016\n",
    "def avg_data_2017(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2017.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2017\n",
    "def avg_data_2018(): \n",
    "    temp_i = 0\n",
    "    average = []\n",
    "    # selecting the the 24 records which condtitute a single day \n",
    "    for rows in pd.read_csv(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\AQI\\\\aqi2018.csv\",chunksize=24):\n",
    "        add_var = 0\n",
    "        avg = 0\n",
    "        data =[]\n",
    "        df = pd.DataFrame(data=rows) # converting the selected rows into a dataframe\n",
    "        for index,row in df.iterrows():\n",
    "            data.append(row[\"PM2.5\"])# appending all the 24 samples pertaining to pm2.5 to data\n",
    "        for i in data:\n",
    "            if type(i) is float or type(i) is int:\n",
    "                add_var = add_var + i \n",
    "            elif type(i) is str:\n",
    "                if i!= \"NoData\" and i!= \"PwrFail\" and i!= \"---\" and i!= \"InVld\": # ignoring null and other unwanted values\n",
    "                    temp = float(i)\n",
    "                    add_var = add_var + temp\n",
    "        avg = add_var/24\n",
    "        temp_i = temp_i +1\n",
    "        average.append(avg)\n",
    "    return average #returning the total average of pm2.5 for year 2018\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  # defining a main function\n",
    "    lst2013 = avg_data_2013()\n",
    "    lst2014 = avg_data_2014()\n",
    "    lst2015 = avg_data_2015()\n",
    "    lst2016 = avg_data_2016()\n",
    "    lst2017 = avg_data_2017()\n",
    "    lst2018 = avg_data_2018()\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def meta_data(month,year):\n",
    "    file_html = open(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\html_data\\\\{}\\\\{}.html\".format(year,month),'rb')\n",
    "    plain_text = file_html.read()\n",
    "    tempD = []\n",
    "    finalD = []\n",
    "    \n",
    "    soup = BeautifulSoup(plain_text,\"lxml\")\n",
    "    for table in soup.find_all('table',{'class':'medias'}):\n",
    "        for tbody in table:\n",
    "            for tr in tbody:\n",
    "                a=tr.get_text()\n",
    "                tempD.append(a)\n",
    "    rows = len(tempD)/15\n",
    "    \n",
    "    for times in range(round(rows)):\n",
    "        newtempD = []\n",
    "        for i in range(15):\n",
    "            newtempD.append(tempD[0])\n",
    "            tempD.pop(0)\n",
    "        finalD.append(newtempD)\n",
    "    length = len(finalD)\n",
    "    finalD.pop(length-1)\n",
    "    finalD.pop(0)\n",
    "    \n",
    "    for a in range(len(finalD)):\n",
    "        finalD[a].pop(6)\n",
    "        finalD[a].pop(4)\n",
    "        finalD[a].pop(13)\n",
    "        finalD[a].pop(12)\n",
    "        finalD[a].pop(11)\n",
    "        finalD[a].pop(10)\n",
    "        finalD[a].pop(9)\n",
    "        finalD[a].pop(0)\n",
    "    return finalD\n",
    "def data_combine(year,cs):\n",
    "    for a in pd.read_csv('C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\\\\real_'+ str(year)+ '.csv',chunksize=cs):\n",
    "        df = pd.DataFrame(data = a)\n",
    "        mylist = df.values.tolist()\n",
    "    return mylist\n",
    "\n",
    "if __name__ ==\"__main__\" :\n",
    "    if not os.path.exists(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\"):\n",
    "        os.makedirs(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\")\n",
    "    for year in range(2013,2017):\n",
    "        final_data = []\n",
    "        with open(\"C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\\\\real_\"+ str(year)+ \".csv\",\"w\") as csvfile:\n",
    "            wr = csv.writer(csvfile,dialect = 'excel')\n",
    "            wr.writerow(['T','TM','Tm','SLP','H','W','V','VH','PM 2.5'])\n",
    "        for month in range(1,13):\n",
    "                temp = meta_data(month,year)\n",
    "                final_data = final_data + temp\n",
    "    \n",
    "        pm = getattr(sys.modules[__name__],'avg_data_{}'.format(year))()\n",
    "            \n",
    "        for i in range(len(final_data)-1):\n",
    "            final_data[i].insert(8,pm[i])\n",
    "        with open('C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\\\\real_'+ str(year)+ \".csv\",'a') as csvfile:\n",
    "            wr = csv.writer(csvfile,dialect = 'excel')\n",
    "            for row in final_data:\n",
    "                flag = 0\n",
    "                for elem in row:\n",
    "                    if elem ==\"\" or elem ==\"-\":\n",
    "                        flag = 1\n",
    "                    if flag!=1:\n",
    "                        wr.writerow(row)\n",
    "    data_2013 = data_combine(2013,600)\n",
    "    data_2014 = data_combine(2014,600)\n",
    "    data_2015 = data_combine(2015,600)\n",
    "    data_2016 = data_combine(2016,600)\n",
    "\n",
    "    total = data_2013+data_2014+data_2015+data_2016\n",
    "\n",
    "    with open('C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\\\\real_combine.csv','w') as csvfile:\n",
    "        wr = csv.writer(csvfile,dialect = 'excel')\n",
    "        wr.writerow(['T','TM','Tm','SLP,'H','W','V','VH','PM 2.5'])\n",
    "        wr.writerows(total)\n",
    "\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>TM</th>\n",
       "      <th>Tm</th>\n",
       "      <th>SLP</th>\n",
       "      <th>H</th>\n",
       "      <th>W</th>\n",
       "      <th>V</th>\n",
       "      <th>VH</th>\n",
       "      <th>PM 2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>284.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>284.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-</td>\n",
       "      <td>93</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11.1</td>\n",
       "      <td>284.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>-</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>219.720833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>182.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2232</td>\n",
       "      <td>14.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-</td>\n",
       "      <td>76</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>186.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2233</td>\n",
       "      <td>14.4</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-</td>\n",
       "      <td>76</td>\n",
       "      <td>0.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>16.5</td>\n",
       "      <td>186.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2234</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-</td>\n",
       "      <td>67</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>185.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2235</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-</td>\n",
       "      <td>67</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>185.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2236</td>\n",
       "      <td>14.3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-</td>\n",
       "      <td>67</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>185.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2237 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         T    TM   Tm SLP   H    W    V    VH      PM 2.5\n",
       "0      8.9    15  5.0   -  93  0.5  4.8  11.1  284.795833\n",
       "1      8.9    15  5.0   -  93  0.5  4.8  11.1  284.795833\n",
       "2      8.9    15  5.0   -  93  0.5  4.8  11.1  284.795833\n",
       "3      9.2     -  4.0   -  97  0.5  9.4  16.5  219.720833\n",
       "4      6.6    10  3.0   -  99  0.6  8.1  13.0  182.187500\n",
       "...    ...   ...  ...  ..  ..  ...  ...   ...         ...\n",
       "2232  14.4  23.0  8.0   -  76  0.8  9.4  16.5  186.041667\n",
       "2233  14.4  23.0  8.0   -  76  0.8  9.4  16.5  186.041667\n",
       "2234  14.3  23.0  7.0   -  67  0.8  4.3  16.5  185.583333\n",
       "2235  14.3  23.0  7.0   -  67  0.8  4.3  16.5  185.583333\n",
       "2236  14.3  23.0  7.0   -  67  0.8  4.3  16.5  185.583333\n",
       "\n",
       "[2237 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\tarun\\\\Desktop\\\\datasets\\\\Pridicting_Air_Quality_ML\\\\Delhidata\\\\Real-data\\\\real_combine.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
